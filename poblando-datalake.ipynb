{"cells":[{"cell_type":"markdown","source":["# POBLANDO DATALAKE - INTRODUCCIÓN APACHE SPARK"],"metadata":{}},{"cell_type":"markdown","source":["## POBLANDO CAPA LANDING\n","**1° PASO** Importamos módulos de apache spark"],"metadata":{}},{"cell_type":"code","execution_count":84,"source":["from pyspark.sql import SparkSession\r\n","from pyspark.sql.types import *\r\n","from pyspark.sql.functions import *"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**2° PASO** Creamos las session de apache spark en una variable"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**3° PASO** Verificamos la versión de apache spark"],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["spark"],"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-1b8d-m.us-central1-c.c.dark-diagram-322105.internal:34977\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.8</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fc6c4515cd0>"]},"metadata":{},"execution_count":4}],"metadata":{}},{"cell_type":"markdown","source":["### CAPA LANDING - PERSONAS\n","\n","**4° PASO** Crear un dataframe\n","\n","* Crear la estructura del dataframe\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de origen\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Cantidad de registros del dataframe\n","* Mostrar las estadísticas básicas de un campo determinado"],"metadata":{}},{"cell_type":"code","execution_count":62,"source":["# 4.1 Estructura del dataframe.\r\n","df_schema = StructType([\r\n","StructField(\"ID\", StringType(),True),\r\n","StructField(\"NOMBRE\", StringType(),True),\r\n","StructField(\"TELEFONO\", StringType(),True),\r\n","StructField(\"CORREO\", StringType(),True),\r\n","StructField(\"FECHA_INGRESO\", StringType(),True),\r\n","StructField(\"EDAD\", IntegerType(),True),\r\n","StructField(\"SALARIO\", DoubleType(),True),\r\n","StructField(\"ID_EMPRESA\", StringType(),True),\r\n","])\r\n","\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":63,"source":["# 4.2 Definimos ruta del archivo\r\n","\r\n","ruta_archivo_google_cloud = \"gs://introduccion-apache-spark/datalake/workload/personas/persona.data\"\r\n","\r\n","ruta_archivo_databricks = \"/FileStore/tables/persona.data\"\r\n","\r\n","ruta_archivo_hdfs = \"hdfs:/introduccion-apache-spark/datalake/workload/personas/persona.data\"\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":64,"source":["#4.3 Definimos ruta del archivo\r\n","df_personas = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema).load(ruta_archivo_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":65,"source":["#4.4 Mostramos la estructura del dataframe.\r\n","df_personas.printSchema()"],"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- NOMBRE: string (nullable = true)\n"," |-- TELEFONO: string (nullable = true)\n"," |-- CORREO: string (nullable = true)\n"," |-- FECHA_INGRESO: string (nullable = true)\n"," |-- EDAD: integer (nullable = true)\n"," |-- SALARIO: double (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n","\n"]}],"metadata":{}},{"cell_type":"code","execution_count":66,"source":["# 4.5 Mostraremos todos los datos del dataframe.\r\n","df_personas.show(5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","only showing top 5 rows\n","\n"]}],"metadata":{}},{"cell_type":"code","execution_count":67,"source":["# 4.6 Mostraremos todos los datos del dataframe.\r\n","num_rows = df_personas.count()\r\n","\r\n","print(\"La cantidad de registro del dataframe es: \", num_rows)"],"outputs":[{"output_type":"stream","name":"stdout","text":["La cantidad de registro del dataframe es:  100\n"]}],"metadata":{}},{"cell_type":"code","execution_count":68,"source":["# 4.7 Estadísticas de un campo determinado.\r\n","df_personas.describe('salario').show()"],"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-----------------+\n","|summary|          salario|\n","+-------+-----------------+\n","|  count|              100|\n","|   mean|         11684.55|\n","| stddev|6841.493958437246|\n","|    min|           1256.0|\n","|    max|          24575.0|\n","+-------+-----------------+\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**5° PASO** Guardar el dataframe en un ruta de la capa landing"],"metadata":{}},{"cell_type":"code","execution_count":35,"source":["ruta_destino_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/personas/\"\r\n","\r\n","ruta_destino_databricks = \"/FileStore/tables/landing/personas/\"\r\n","\r\n","ruta_destino_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/personas/\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":69,"source":["df_personas.write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### CAPA LANDING -  EMPRESAS \n","**6° PASO** Realizar la ingesta de Empresas en la capa landing\n","* Crear estructura del dataframe.\n","* Definir la ruta del archivo.\n","* Crear la estructura del dataframe\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de origen\n","* Mostrar la información del dataframe\n","* Guardar el dataframe en un ruta de la capa landing"],"metadata":{}},{"cell_type":"code","execution_count":70,"source":["# 6.1 Estructura del dataframe.\r\n","df_schema_empresas = StructType([\r\n","StructField(\"ID\", StringType(),True),\r\n","StructField(\"EMPRESA_NAME\", StringType(),True)\r\n","])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":71,"source":["# 6.2 Definimos ruta del archivo\r\n","\r\n","ruta_archivo_google_cloud = \"gs://introduccion-apache-spark/datalake/workload/empresas/empresa.data\"\r\n","\r\n","ruta_archivo_databricks = \"/FileStore/tables/empresa.data\"\r\n","\r\n","ruta_archivo_hdfs = \"hdfs:/introduccion-apache-spark/datalake/workload/empresas/empresa.data\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":72,"source":["# 6.3 Creamos el dataframe \r\n","df_empresas = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema_empresas).load(ruta_archivo_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":73,"source":["# 6.4 Mostramos registros del dataframe\r\n","df_empresas.show(10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  1|     Walmart|\n","|  2|   Microsoft|\n","|  3|       Apple|\n","|  4|      Toyota|\n","|  5|      Amazon|\n","|  6|      Google|\n","|  7|     Samsung|\n","|  8|          HP|\n","|  9|         IBM|\n","| 10|        Sony|\n","+---+------------+\n","\n"]}],"metadata":{}},{"cell_type":"code","execution_count":74,"source":["# 6.5 Definimos la ruta de almacenamiento\r\n","\r\n","ruta_destino_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/empresas/\"\r\n","\r\n","ruta_destino_databricks = \"/FileStore/tables/landing/empresas/\"\r\n","\r\n","ruta_destino_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/empresas/\"\r\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":75,"source":["# 6.6 Guardamos el archivo en formato parquet\r\n","df_empresas.repartition(2).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## POBLANDO CAPA CURATED"],"metadata":{}},{"cell_type":"markdown","source":["### PERSONAS\n","**7° PASO** Definimos ruta del archivo"],"metadata":{}},{"cell_type":"code","execution_count":90,"source":["ruta_landing_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/personas/\"\r\n","\r\n","ruta_landing_databricks = \"/FileStore/tables/landing/personas/\"\r\n","\r\n","ruta_landing_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/personas/\""],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**8° PASO** Creamos el dataframe de Persona"],"metadata":{}},{"cell_type":"code","execution_count":91,"source":["df_personas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_landing_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**9° PASO** Mostramos el dataframe cargado en memoria"],"metadata":{}},{"cell_type":"code","execution_count":92,"source":["df_personas_landing.show(10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|      797-4453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|1-680-102-6792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|      214-2975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|      935-2277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|1-866-561-2701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**10° PASO** Mostramos el schema del dataframe"],"metadata":{}},{"cell_type":"code","execution_count":93,"source":["df_personas_landing.printSchema()"],"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- NOMBRE: string (nullable = true)\n"," |-- TELEFONO: string (nullable = true)\n"," |-- CORREO: string (nullable = true)\n"," |-- FECHA_INGRESO: string (nullable = true)\n"," |-- EDAD: integer (nullable = true)\n"," |-- SALARIO: double (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**11° PASO** Realizamos la limpieza del dataframe"],"metadata":{}},{"cell_type":"code","execution_count":94,"source":["df_personas_procesado = df_personas_landing.withColumn('telefono', regexp_replace('telefono', '-', ''))\r\n","df_personas_procesado.show(10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**12° PASO** Definir ruta de almacenamiento en la capa curated"],"metadata":{}},{"cell_type":"code","execution_count":95,"source":["ruta_curated_personas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/personas/\"\r\n","\r\n","ruta_curated_personas_databricks = \"/FileStore/tables/curated/personas/\"\r\n","\r\n","ruta_curated_personas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/curated/personas/\"\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**13° PASO** Definir ruta de almacenamiento en la capa curated"],"metadata":{}},{"cell_type":"code","execution_count":96,"source":["df_personas_procesado.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_curated_personas_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["### EMPRESAS\n","**14° PASO** Realizar la ingesta de Empresas en Curated\n","\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de la capa landing\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Realizar una limpieza al dataframe\n","* Guardar el dataframe en un ruta de la capa curated"],"metadata":{}},{"cell_type":"code","execution_count":89,"source":["# 14.1 variable la ruta del archivo\r\n","ruta_landing_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/empresas/\"\r\n","\r\n","ruta_landing_empresas_databricks = \"/FileStore/tables/landing/empresas/\"\r\n","\r\n","ruta_landing_empresas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/empresas/\"\r\n","\r\n","# 14.2 Leer el archivo de la capa landing\r\n","df_empresas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_landing_empresas_google_cloud)\r\n","\r\n","# 14.3 Mostrar la estructura del dataframe\r\n","df_empresas_landing.printSchema()\r\n","\r\n","#14.4 Mostrar los datos del dataframe\r\n","df_empresas_landing.show(5)\r\n","\r\n","#14.5 Realizar limpieza a dataframe\r\n","df_empresas_procesado = df_empresas_landing.withColumn('EMPRESA_NAME',upper(col('EMPRESA_NAME')))\r\n","\r\n","#14.6 Mostrar los datos procesado\r\n","df_empresas_procesado.show(5)\r\n","\r\n","#14. Definir ruta de curated\r\n","ruta_curated_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/empresas/\"\r\n","\r\n","ruta_curated_empresas_databricks = \"/FileStore/tables/curated/empresas/\"\r\n","\r\n","ruta_curated_empresas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/curated/empresas/\"\r\n","\r\n","# 14.6 Guardar daframe en capa curated\r\n","\r\n","df_empresas_procesado.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_curated_empresas_google_cloud)\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- EMPRESA_NAME: string (nullable = true)\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      Amazon|\n","|  6|      Google|\n","|  4|      Toyota|\n","|  7|     Samsung|\n","|  3|       Apple|\n","+---+------------+\n","only showing top 5 rows\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      AMAZON|\n","|  6|      GOOGLE|\n","|  4|      TOYOTA|\n","|  7|     SAMSUNG|\n","|  3|       APPLE|\n","+---+------------+\n","only showing top 5 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## POBLANDO CAPA FUNCTIONAL"],"metadata":{}},{"cell_type":"markdown","source":["**PASO 15°** Obteniendo información requeridad para el analisis de **Salario x Empresa**"],"metadata":{}},{"cell_type":"markdown","source":["**15.1** Definimos ruta tablas requeridas apuntando a la capa curated "],"metadata":{}},{"cell_type":"code","execution_count":99,"source":["ruta_curated_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/empresas/\"\r\n","\r\n","ruta_curated_personas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/personas/\""],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**15.2** Creamos el dataframe para cada tabla."],"metadata":{}},{"cell_type":"code","execution_count":100,"source":["df_personas_curated = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_curated_personas_google_cloud)\r\n","\r\n","df_empresas_curated = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_curated_empresas_google_cloud)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**15.3** Mostramos datos de los dataframes"],"metadata":{}},{"cell_type":"code","execution_count":101,"source":["df_personas_curated.show(5)\r\n","df_empresas_curated.show(5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","only showing top 5 rows\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      AMAZON|\n","|  6|      GOOGLE|\n","|  4|      TOYOTA|\n","|  7|     SAMSUNG|\n","|  3|       APPLE|\n","+---+------------+\n","only showing top 5 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**15.4** Realizar la unión (join) de ambas tablas "],"metadata":{}},{"cell_type":"code","execution_count":103,"source":["df_join = df_personas_curated.join(df_empresas_curated, df_personas_curated.ID_EMPRESA == df_empresas_curated.ID)\r\n","df_join.show()"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n","|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|  7|     SAMSUNG|\n","|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|  5|      AMAZON|\n","|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|  5|      AMAZON|\n","|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|  3|       APPLE|\n","| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|  7|     SAMSUNG|\n","| 11|  Melyssa|    5967736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|  8|          HP|\n","| 12|   Tanner|17397767897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|  8|          HP|\n","| 13|   Trevor|    5121955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|  5|      AMAZON|\n","| 14|    Allen|    7332795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|  2|   MICROSOFT|\n","| 15|    Wanda|    3596973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|  5|      AMAZON|\n","| 16|    Alden|    3418522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|  2|   MICROSOFT|\n","| 17|     Omar|    7201543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|  6|      GOOGLE|\n","| 18|     Owen|11673357541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|  7|     SAMSUNG|\n","| 19|    Laura|19746232057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|  4|      TOYOTA|\n","| 20|    Emery|16728400264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|  9|         IBM|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","only showing top 20 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**15.5**  Realizar la unión (join) de ambas tablas utilizando **Spark SQL**"],"metadata":{}},{"cell_type":"code","execution_count":104,"source":["df_personas_curated.createOrReplaceTempView(\"tb_personas\")\r\n","df_empresas_curated.createOrReplaceTempView(\"tb_empresas\")\r\n","\r\n","df_sql = spark.sql(\"SELECT * FROM tb_personas p inner join tb_empresas e on e.ID = p.ID_EMPRESA\")\r\n","df_sql.show(5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","only showing top 5 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**15.6** Seleccionar campos requeridos para el análisis "],"metadata":{}},{"cell_type":"code","execution_count":105,"source":["df_select = df_join.select(col('EDAD'),col('SALARIO'),col('EMPRESA_NAME'))\r\n","df_select.show()"],"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+------------+\n","|EDAD|SALARIO|EMPRESA_NAME|\n","+----+-------+------------+\n","|  32|20095.0|      AMAZON|\n","|  34| 9298.0|   MICROSOFT|\n","|  27|10853.0|       APPLE|\n","|  29| 3387.0|        SONY|\n","|  41|22102.0|     WALMART|\n","|  70| 7800.0|     SAMSUNG|\n","|  52| 8112.0|      AMAZON|\n","|  23|17040.0|      AMAZON|\n","|  69| 6834.0|       APPLE|\n","|  19| 7996.0|     SAMSUNG|\n","|  48| 4913.0|          HP|\n","|  24|19943.0|          HP|\n","|  34| 9501.0|      AMAZON|\n","|  59|16289.0|   MICROSOFT|\n","|  27| 1539.0|      AMAZON|\n","|  26| 3377.0|   MICROSOFT|\n","|  60| 6851.0|      GOOGLE|\n","|  34| 4759.0|     SAMSUNG|\n","|  70|17403.0|      TOYOTA|\n","|  24|18752.0|         IBM|\n","+----+-------+------------+\n","only showing top 20 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["**15.7** Definimos la ruta de functional y persistimos los registros"],"metadata":{}},{"cell_type":"code","execution_count":106,"source":["ruta_functional = \"gs://introduccion-apache-spark/datalake/functional/salario_empresa/\"\r\n","\r\n","df_select.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_functional)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["**15.8** Consultamos la información almacenada en Funcional"],"metadata":{}},{"cell_type":"code","execution_count":107,"source":["df_salario_empresa = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_functional)\r\n","df_salario_empresa.show(10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------+------------+\n","|EDAD|SALARIO|EMPRESA_NAME|\n","+----+-------+------------+\n","|  32|20095.0|      AMAZON|\n","|  34| 9298.0|   MICROSOFT|\n","|  27|10853.0|       APPLE|\n","|  29| 3387.0|        SONY|\n","|  41|22102.0|     WALMART|\n","|  70| 7800.0|     SAMSUNG|\n","|  52| 8112.0|      AMAZON|\n","|  23|17040.0|      AMAZON|\n","|  69| 6834.0|       APPLE|\n","|  19| 7996.0|     SAMSUNG|\n","+----+-------+------------+\n","only showing top 10 rows\n","\n"]}],"metadata":{}},{"cell_type":"markdown","source":["\n","# Felicitaciones por completar el curso de Introducción Apache Spark\n","#### **Elaborado por** Juan Salinas\n","#### Linkedin: https://www.linkedin.com/in/juan-salinas/"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}
